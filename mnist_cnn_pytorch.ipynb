{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import tensorwatch as tw\n",
    "\n",
    "import tensorpack.dataflow as df\n",
    "\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0608 17:33:04 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /Users/tmquan/tensorpack_data for datasets.\n",
      "\u001b[32m[0608 17:33:04 @parallel.py:194]\u001b[0m [MultiProcessPrefetchData] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n",
      "\u001b[32m[0608 17:33:04 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is not safe and may consume unnecessary extra memory. Use 'forkserver' method (available after Py3.4) instead if you run into any issues. See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "ds = df.dataset.Mnist('train')\n",
    "augmentors_variation = [\n",
    "    df.imgaug.Resize((28, 28)),\n",
    "    df.imgaug.CenterPaste((32, 32)),\n",
    "    df.imgaug.RandomCrop((28, 28)),\n",
    "\n",
    "    #df.imgaug.MapImage(lambda v: v.reshape(784))\n",
    "    df.imgaug.MapImage(lambda v: np.expand_dims(v, 0))\n",
    "]\n",
    "ds = df.AugmentImageComponent(ds, augmentors_variation)\n",
    "ds = df.PrefetchData(ds, nr_prefetch=100, nr_proc=4)\n",
    "ds = df.PrintData(ds)\n",
    "ds = df.BatchData(ds, batch_size=100, remainder=False, use_list=False)\n",
    "ds = df.PrintData(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:00, step:000100, loss:2.289, accuracy:15.000\n",
      "epoch:00, step:000200, loss:2.299, accuracy:15.000\n",
      "epoch:00, step:000300, loss:2.290, accuracy:16.000\n",
      "epoch:00, step:000400, loss:2.266, accuracy:17.000\n",
      "epoch:00, step:000500, loss:2.259, accuracy:21.000\n",
      "epoch:00, step:000600, loss:2.234, accuracy:26.000\n",
      "epoch:01, step:000700, loss:2.135, accuracy:26.000\n",
      "epoch:01, step:000800, loss:2.073, accuracy:30.000\n",
      "epoch:01, step:000900, loss:1.702, accuracy:51.000\n",
      "epoch:01, step:001000, loss:1.609, accuracy:46.000\n",
      "epoch:01, step:001100, loss:1.502, accuracy:45.000\n",
      "epoch:01, step:001200, loss:1.532, accuracy:48.000\n",
      "epoch:02, step:001300, loss:1.342, accuracy:57.000\n",
      "epoch:02, step:001400, loss:1.200, accuracy:61.000\n",
      "epoch:02, step:001500, loss:1.284, accuracy:56.000\n",
      "epoch:02, step:001600, loss:1.116, accuracy:64.000\n",
      "epoch:02, step:001700, loss:1.058, accuracy:61.000\n",
      "epoch:02, step:001800, loss:1.049, accuracy:67.000\n",
      "epoch:03, step:001900, loss:1.204, accuracy:57.000\n",
      "epoch:03, step:002000, loss:1.115, accuracy:65.000\n",
      "epoch:03, step:002100, loss:1.114, accuracy:63.000\n",
      "epoch:03, step:002200, loss:1.029, accuracy:66.000\n",
      "epoch:03, step:002300, loss:0.803, accuracy:76.000\n",
      "epoch:03, step:002400, loss:0.810, accuracy:77.000\n",
      "epoch:04, step:002500, loss:0.892, accuracy:69.000\n",
      "epoch:04, step:002600, loss:0.828, accuracy:70.000\n",
      "epoch:04, step:002700, loss:1.055, accuracy:63.000\n",
      "epoch:04, step:002800, loss:0.898, accuracy:70.000\n",
      "epoch:04, step:002900, loss:1.091, accuracy:64.000\n",
      "epoch:04, step:003000, loss:1.061, accuracy:67.000\n",
      "epoch:05, step:003100, loss:0.868, accuracy:73.000\n",
      "epoch:05, step:003200, loss:0.705, accuracy:74.000\n",
      "epoch:05, step:003300, loss:0.922, accuracy:78.000\n",
      "epoch:05, step:003400, loss:0.774, accuracy:77.000\n",
      "epoch:05, step:003500, loss:0.757, accuracy:80.000\n",
      "epoch:05, step:003600, loss:0.682, accuracy:78.000\n",
      "epoch:06, step:003700, loss:0.641, accuracy:81.000\n",
      "epoch:06, step:003800, loss:0.664, accuracy:75.000\n",
      "epoch:06, step:003900, loss:0.772, accuracy:75.000\n",
      "epoch:06, step:004000, loss:0.822, accuracy:71.000\n",
      "epoch:06, step:004100, loss:0.763, accuracy:74.000\n",
      "epoch:06, step:004200, loss:0.700, accuracy:79.000\n",
      "epoch:07, step:004300, loss:0.862, accuracy:74.000\n",
      "epoch:07, step:004400, loss:0.713, accuracy:79.000\n",
      "epoch:07, step:004500, loss:0.678, accuracy:84.000\n",
      "epoch:07, step:004600, loss:0.976, accuracy:75.000\n",
      "epoch:07, step:004700, loss:0.566, accuracy:81.000\n",
      "epoch:07, step:004800, loss:0.593, accuracy:85.000\n",
      "epoch:08, step:004900, loss:0.542, accuracy:82.000\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "# train\n",
    "step = 0\n",
    "for epoch in range(30):\n",
    "    for minibatch in ds.get_data():\n",
    "        images = Variable(torch.from_numpy(minibatch[0]))\n",
    "        labels = Variable(torch.from_numpy(minibatch[1].astype(np.int64)))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = torch.nn.functional.nll_loss(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        l = loss.data #[0]\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        a = pred.eq(labels.data.view_as(pred)).cpu().sum() #/ 128.0\n",
    "        step += 1\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('epoch:{:02d}, step:{:06d}, loss:{:.3f}, accuracy:{:.3f}'.format(epoch, step, l, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
